{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a21c960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8bcf86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       user_id  user_id_encoded  \\\n",
      "878270    67364097-11ac-4efe-a716-00c7b6388ad3             3634   \n",
      "33363377  84ba2477-abe7-4399-abcb-ba3fbe1d4b99             4681   \n",
      "13472745  19ad77bf-1264-429e-8d95-87891f5bc9bd              933   \n",
      "24159069  ba6d46f8-c2ea-4531-8ee2-9ddace35f24e             6534   \n",
      "12069240  8fb2a78c-d48b-4035-80d0-5dfbd235cd07             5057   \n",
      "\n",
      "                                      video_id  video_id_encoded  \n",
      "878270    6e0efb88-e04c-4244-8e5d-880c87a1d74b            669635  \n",
      "33363377  549be903-bfe7-4699-9320-70214743676c            514700  \n",
      "13472745  f31f9451-fe62-4a39-a70e-903a000131ad           1477300  \n",
      "24159069  2d097c02-afaa-4006-99de-d4abff4ed5dc            273865  \n",
      "12069240  f7958100-4ad3-43d4-8fa4-f95cb383a119           1504393  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Пример загрузки малой части данных\n",
    "# Загрузка первых 10000 строк для примера \n",
    "video_data = pd.read_parquet('video_stat.parquet')\n",
    "log_data = pd.read_parquet('logs_df_2024-08-05.parquet', engine='pyarrow')\n",
    "\n",
    "# Используем малую часть данных для ускорения процесса\n",
    "log_data = log_data.sample(10000, random_state=42)  # Подгружаем случайную часть данных\n",
    "\n",
    "# Проверка и замена пропущенных значений\n",
    "video_data = video_data.dropna(subset=['video_id'])  # Удаляем строки с пропущенными 'video_id'\n",
    "log_data = log_data.dropna(subset=['video_id', 'user_id'])  # Удаляем строки с пропущенными 'video_id' и 'user_id'\n",
    "\n",
    "# Кодирование идентификаторов видео и пользователей\n",
    "video_encoder = LabelEncoder()\n",
    "user_encoder = LabelEncoder()\n",
    "\n",
    "# Кодирование данных\n",
    "video_data['video_id_encoded'] = video_encoder.fit_transform(video_data['video_id'])\n",
    "\n",
    "# Проверка и корректировка: удаление значений, отсутствующих в обучающем наборе\n",
    "log_data = log_data[log_data['video_id'].isin(video_data['video_id'])]\n",
    "\n",
    "log_data['video_id_encoded'] = video_encoder.transform(log_data['video_id'])\n",
    "log_data['user_id_encoded'] = user_encoder.fit_transform(log_data['user_id'])\n",
    "\n",
    "# Проверка корректности кодирования\n",
    "print(log_data[['user_id', 'user_id_encoded', 'video_id', 'video_id_encoded']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f123ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание последовательностей для обучения\n",
    "X, y = [], []\n",
    "for user_id in log_data['user_id'].unique():\n",
    "    user_logs = log_data[log_data['user_id'] == user_id]\n",
    "    seq = user_logs['video_id_encoded'].tolist()\n",
    "    for i in range(1, len(seq)):\n",
    "        X.append(seq[:i])  # Все до текущего\n",
    "        y.append(seq[i])   # Текущее видео\n",
    "\n",
    "# Преобразование данных в массивы и ограничение длины последовательностей\n",
    "max_seq_len = 50  # Ограничим длину последовательностей\n",
    "X = [x[-max_seq_len:] for x in X]  # Ограничим длину последовательности\n",
    "X = [np.pad(x, (max_seq_len - len(x), 0), mode='constant') for x in X]  # Паддинг последовательностей\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86c173e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a439621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание класса Dataset для PyTorch\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Создание DataLoader для загрузки данных батчами\n",
    "train_dataset = VideoDataset(X_train, y_train)\n",
    "val_dataset = VideoDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d3a3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели\n",
    "class VideoRecommendationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=50, hidden_dim=100, output_dim=None):\n",
    "        super(VideoRecommendationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        out = self.fc(hidden)\n",
    "        return out\n",
    "\n",
    "# Инициализация модели, функции потерь и оптимизатора\n",
    "vocab_size = len(video_encoder.classes_)\n",
    "model = VideoRecommendationModel(vocab_size=vocab_size, output_dim=vocab_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf97eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция тренировки модели\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f499543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 14.253737926483154, Val Loss: 14.268963813781738\n",
      "Epoch 2/5, Train Loss: 14.186275005340576, Val Loss: 14.26468276977539\n",
      "Epoch 3/5, Train Loss: 14.117308139801025, Val Loss: 14.258644104003906\n",
      "Epoch 4/5, Train Loss: 14.03763723373413, Val Loss: 14.252567291259766\n",
      "Epoch 5/5, Train Loss: 13.941096305847168, Val Loss: 14.24657917022705\n"
     ]
    }
   ],
   "source": [
    "# Запуск тренировки\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea66111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена по пути: video_recommendation_model.pth\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Путь для сохранения модели\n",
    "model_save_path = 'video_recommendation_model.pth'\n",
    "\n",
    "# Сохранение модели после тренировки\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Модель сохранена по пути: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff05837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
